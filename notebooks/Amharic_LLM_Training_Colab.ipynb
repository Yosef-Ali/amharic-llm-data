{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üöÄ Amharic LLM Training on Google Colab\n",
        "\n",
        "This notebook trains an Amharic language model using your collected dataset.\n",
        "\n",
        "**Setup Instructions:**\n",
        "1. Runtime ‚Üí Change runtime type ‚Üí GPU (T4)\n",
        "2. Run all cells in order\n",
        "3. Training will take 10-30 minutes depending on model size\n",
        "\n",
        "**Models Available:**\n",
        "- `distilgpt2` (82M) - Ultra fast (5-10 min)\n",
        "- `gpt2` (124M) - Fast (10-15 min)\n",
        "- `bloom-560m` (560M) - Balanced (20-30 min)\n",
        "- `bloom-1b1` (1.1B) - Quality (45-60 min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive for data persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create directory for models\n",
        "!mkdir -p /content/drive/MyDrive/amharic_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "# Setup data - Choose one of the options below\n",
        "\n",
        "# Option 1: Upload to Google Drive (RECOMMENDED)\n",
        "# 1. Upload your 'amharic-llm-data' folder to Google Drive\n",
        "# 2. Uncomment and run the lines below:\n",
        "# !cp -r '/content/drive/MyDrive/amharic-llm-data' /content/\n",
        "# %cd /content/amharic-llm-data\n",
        "\n",
        "# Option 2: Clone from GitHub (if you've pushed the data)\n",
        "!git clone https://github.com/Yosef-Ali/amharic-llm-data.git\n",
        "%cd amharic-llm-data\n",
        "\n",
        "# Option 3: Direct file upload\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()  # Upload your dataset files manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_requirements"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers datasets peft accelerate bitsandbytes\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_data"
      },
      "outputs": [],
      "source": [
        "# Check dataset\n",
        "!ls -la data/processed/\n",
        "\n",
        "# Show dataset statistics\n",
        "import json\n",
        "with open('data/dataset_statistics.json', 'r') as f:\n",
        "    stats = json.load(f)\n",
        "    print(f\"Total examples: {stats['total_examples']}\")\n",
        "    print(f\"Train: {stats['train_size']}, Val: {stats['validation_size']}, Test: {stats['test_size']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "training_options"
      },
      "outputs": [],
      "source": [
        "# Show training options\n",
        "!python scripts/fast_training.py --options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_ultra_fast"
      },
      "outputs": [],
      "source": [
        "# ULTRA FAST Training (5-10 minutes)\n",
        "# Good for testing the pipeline\n",
        "\n",
        "!python scripts/fast_training.py --train --model distilgpt2 --steps 100 --output models/amharic-distilgpt2\n",
        "\n",
        "# Copy to Google Drive\n",
        "!cp -r models/amharic-distilgpt2 /content/drive/MyDrive/amharic_models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_balanced"
      },
      "outputs": [],
      "source": [
        "# BALANCED Training (20-30 minutes)\n",
        "# Good balance of speed and quality\n",
        "\n",
        "!python scripts/fast_training.py --train --model bloom-560m --steps 300 --output models/amharic-bloom560m\n",
        "\n",
        "# Copy to Google Drive\n",
        "!cp -r models/amharic-bloom560m /content/drive/MyDrive/amharic_models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_quality"
      },
      "outputs": [],
      "source": [
        "# QUALITY Training (45-60 minutes)\n",
        "# Best quality for production use\n",
        "\n",
        "!python scripts/fast_training.py --train --model bloom-1b1 --steps 500 --output models/amharic-bloom1b1\n",
        "\n",
        "# Copy to Google Drive\n",
        "!cp -r models/amharic-bloom1b1 /content/drive/MyDrive/amharic_models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_model"
      },
      "outputs": [],
      "source": [
        "# Test the trained model\n",
        "!python scripts/fast_training.py --test --output models/amharic-bloom560m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "interactive_test"
      },
      "outputs": [],
      "source": [
        "# Interactive testing\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load your trained model\n",
        "model_path = \"models/amharic-bloom560m\"  # Change this to your model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "def generate_response(instruction):\n",
        "    prompt = f\"Instruction: {instruction}\\nResponse:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=100,\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "    \n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response.split(\"Response:\")[-1].strip()\n",
        "\n",
        "# Test with Amharic instructions\n",
        "test_instructions = [\n",
        "    \"·ã®·ä†·àõ·à≠·äõ ·âã·äï·âã ·àù·äï·ãµ·äï ·äê·ãç?\",\n",
        "    \"·ä¢·âµ·ãÆ·åµ·ã´ ·ã®·âµ ·âµ·åà·äõ·àà·âΩ?\",\n",
        "    \"·ã®·ä†·ã≤·àµ ·ä†·â†·â£ ·ãã·äì ·ä®·â∞·àõ ·àù·äï·ãµ·äï ·äê·ãç?\"\n",
        "]\n",
        "\n",
        "for instruction in test_instructions:\n",
        "    response = generate_response(instruction)\n",
        "    print(f\"Q: {instruction}\")\n",
        "    print(f\"A: {response}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload_to_hub"
      },
      "outputs": [],
      "source": [
        "# Upload to Hugging Face Hub (optional)\n",
        "# First, login to Hugging Face\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "\n",
        "# Upload model\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_path = \"models/amharic-bloom560m\"\n",
        "hub_model_name = \"your-username/amharic-bloom-560m\"  # Change this\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "tokenizer.push_to_hub(hub_model_name)\n",
        "model.push_to_hub(hub_model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "## üéâ Training Complete!\n",
        "\n",
        "Your Amharic language model has been trained successfully. Here's what you can do next:\n",
        "\n",
        "### üìÅ Your Models\n",
        "- Models are saved in Google Drive: `/content/drive/MyDrive/amharic_models/`\n",
        "- You can download them or use them in other notebooks\n",
        "\n",
        "### üöÄ Next Steps\n",
        "1. **Test More**: Try different prompts and instructions\n",
        "2. **Deploy**: Create a Gradio demo or API\n",
        "3. **Improve**: Collect more data and retrain\n",
        "4. **Share**: Upload to Hugging Face Hub\n",
        "\n",
        "### üìä Model Comparison\n",
        "- **DistilGPT2**: Fast, good for testing\n",
        "- **Bloom-560M**: Balanced, good for most use cases\n",
        "- **Bloom-1B1**: Best quality, slower training\n",
        "\n",
        "### üîó Useful Links\n",
        "- [Hugging Face Hub](https://huggingface.co)\n",
        "- [Gradio Documentation](https://gradio.app)\n",
        "- [Transformers Documentation](https://huggingface.co/docs/transformers)"
      ]
    }
  ]
}